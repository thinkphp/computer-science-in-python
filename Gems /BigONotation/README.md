# Big O Notation
Big O notation is not a "discipline" in computer science, but rather a fundamental concept in algorithm analysis. It is part of the broader field of computational complexity theory, which studies the efficiency of algorithms in terms of time and space as input sizes grow.

Big O notation helps classify algorithms based on their worst-case or upper-bound performance, making it a crucial tool in software development, competitive programming, and theoretical computer science.
